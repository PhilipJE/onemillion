{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef83b60-3e7a-4789-8455-057c2a8a8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import json\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dca880e-2810-4ca6-8ce7-b834af238d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/15 15:32:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "spark_session = SparkSession.builder\\\n",
    "        .master(\"spark://192.168.2.156:7077\") \\\n",
    "        .appName(\"Group 6 project\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\", 32)\\\n",
    "        .config(\"spark.cores.max\", 32)\\\n",
    "        .config(\"spark.driver.port\",9999)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://192.168.2.156:9000\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(spark_session.sparkContext)\n",
    "spark_session.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ea49151-abf3-41fa-a6d1-4972ba654240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.               (0 + 0) / 147]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/ubuntu/.local/lib/python3.10/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load JSON as a Spark DataFrame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhdfs://192.168.2.156:9000/data/reddit/corpus-webis-tldr-17.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyspark/sql/readwriter.py:425\u001b[0m, in \u001b[0;36mDataFrameReader.json\u001b[0;34m(self, path, schema, primitivesAsString, prefersDecimal, allowComments, allowUnquotedFieldNames, allowSingleQuotes, allowNumericLeadingZero, allowBackslashEscapingAnyCharacter, mode, columnNameOfCorruptRecord, dateFormat, timestampFormat, multiLine, allowUnquotedControlChars, lineSep, samplingRatio, dropFieldIfAllNull, encoding, locale, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, allowNonNumericNumbers)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunc\u001b[39m(iterator: Iterable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load JSON as a Spark DataFrame\n",
    "df = spark_session.read.json(\"hdfs://192.168.2.156:9000/data/reddit/corpus-webis-tldr-17.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47315dc9-b4bf-4b11-8cb2-0fcde52c1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+-----------+-------+--------------------+--------------------+------------+--------------------+-----------+--------+\n",
      "|            author|                body|             content|content_len|     id|      normalizedBody|           subreddit|subreddit_id|             summary|summary_len|   title|\n",
      "+------------------+--------------------+--------------------+-----------+-------+--------------------+--------------------+------------+--------------------+-----------+--------+\n",
      "|  raysofdarkmatter|I think it should...|I think it should...|        178|c69al3r|I think it should...|                math|    t5_2qh0n|Shifting seasonal...|          8|    NULL|\n",
      "|           Stork13|Art is about the ...|Art is about the ...|        148|c6a9nxd|Art is about the ...|               funny|    t5_2qh33|Personal opinions...|          4|    NULL|\n",
      "|     Cloud_dreamer|Ask me what I thi...|Ask me what I thi...|         76|c6acx4l|Ask me what I thi...|         Borderlands|    t5_2r8cd|insults and slack...|         73|    NULL|\n",
      "|     NightlyReaper|In Mechwarrior On...|In Mechwarrior On...|        213|c8onqew|In Mechwarrior On...|            gamingpc|    t5_2sq2y|Yes, Joysticks in...|         19|    NULL|\n",
      "|    NuffZetPand0ra|You are talking a...|You are talking a...|        404|c6acxvc|You are talking a...|              Diablo|    t5_2qore|Class only items ...|          7|D2 help?|\n",
      "|beatlecreedcabaret|All but one of my...|All but one of my...|        130|c6ahuc4|All but one of my...|   RedditLaqueristas|    t5_2se5q|      OPI Nail Envy!|          3|    NULL|\n",
      "|      nobodysdiary|I could give a sh...|I could give a sh...|        156|c6aggux|I could give a sh...|               apple|    t5_2qh1f|I don't drive lik...|         18|    NULL|\n",
      "|          chrom_ed|So you're saying ...|So you're saying ...|        134|c6agxtv|So you're saying ...|               apple|    t5_2qh1f|you don't seem to...|          9|    NULL|\n",
      "|      gadzookfilms|I love this idea ...|I love this idea ...|        126|c6asb7p|I love this idea ...|RedditFilmsProduc...|    t5_2v33h|How we make money...|          9|    NULL|\n",
      "|      iamacannibal|Theres an entire ...|Theres an entire ...|        181|c6aveyw|Theres an entire ...|       AbandonedPorn|    t5_2sh6t|I'll try and get ...|         25|    NULL|\n",
      "| splagaticusxoxo97|FALSE. Evidence: ...|FALSE. Evidence: ...|        124|c6bacqq|FALSE. Evidence: ...|             atheism|    t5_2qh2p|dont fuck with re...|          6|    NULL|\n",
      "|           orthzar|If the number of ...|If the number of ...|         12|c6b83kp|If the number of ...|              quotes|    t5_2qhdx|                  no|          1|    NULL|\n",
      "|          phyzishy|Yeah, but most fo...|Yeah, but most fo...|         75|c6b52m8|Yeah, but most fo...|           AskReddit|    t5_2qh1i|       stupid stuff.|          2|    NULL|\n",
      "|          Wheelman|As an entrepreneu...|As an entrepreneu...|         78|c6b34c2|As an entrepreneu...|     personalfinance|    t5_2qstm|get a good CPA - ...|         14|    NULL|\n",
      "|        slagahthor|i guess the way I...|i guess the way I...|        323|c6b9gqo|i guess the way I...|             Animals|    t5_2qi0c|Dog neglected for...|          7|    NULL|\n",
      "|        Perservere|Didn't they lose ...|Didn't they lose ...|         86|c6bftvc|Didn't they lose ...|     leagueoflegends|    t5_2rfxx|just because you'...|         23|    NULL|\n",
      "|       fallsuspect|You probably won'...|You probably won'...|         79|c6bncqn|You probably won'...|           AskReddit|    t5_2qh1i|just get both of ...|         11|    NULL|\n",
      "|          captain0|To simply say tha...|To simply say tha...|        328|c6btcx4|To simply say tha...|              videos|    t5_2qh1e| Oppan Gangnam Style|          3|    NULL|\n",
      "|    Buck_Speedjunk|This picture does...|This picture does...|         18|c6c4uks|This picture does...|               trees|    t5_2r9vp|It's a half-assed...|         13|    NULL|\n",
      "|        FrankManic|And that is, hand...|And that is, hand...|         57|c6c7pgn|And that is, hand...|               Games|    t5_2qhwp|Play balance is f...|         13|    NULL|\n",
      "+------------------+--------------------+--------------------+-----------+-------+--------------------+--------------------+------------+--------------------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show() #Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f217d52-99ac-4f56-ab89-7352a5fec993",
   "metadata": {},
   "source": [
    "# Task 1: Reading level in subreddits\n",
    "First, we analyse the language level using Fleschâ€“Kincaid grade level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a879328a-533c-49c3-8df8-ba297548e368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:======================================================>(146 + 1) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length is 3848330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Making a new df for analyzing the reading level\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "# Splitting sentences\n",
    "df_spell = df.select(\"subreddit\", split(df[\"content\"], r'[.!?]').alias(\"content_split\"))\n",
    "\n",
    "# Splitting words, removing punctuation and empty strings\n",
    "df_words = df_spell.withColumn(\"content_split\", expr(\"\"\"transform(content_split, x -> filter(transform(split(x, ' '), word -> trim(regexp_replace(regexp_replace(word, '[\\\\n]', ''), '[,\\\\.\\\\!\\\\?:\\\\*\\\\(\\\\)]', ''))), word -> word != ''))\"\"\"))\n",
    "\n",
    "df_words = df_words.filter(size(df_words[\"content_split\"]) > 0)  # Remove empty rows\n",
    "\n",
    "df_words.first()\n",
    "print(f\"The length is {df_words.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f4da8b9-0e71-42f1-b50f-8a64d14ce981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+\n",
      "|subreddit            |reading_level     |\n",
      "+---------------------+------------------+\n",
      "|math                 |6.725263157894737 |\n",
      "|funny                |8.53345238095238  |\n",
      "|Borderlands          |5.230000000000004 |\n",
      "|gamingpc             |5.300161290322581 |\n",
      "|Diablo               |6.498808026355196 |\n",
      "|RedditLaqueristas    |4.662500000000001 |\n",
      "|apple                |0                 |\n",
      "|apple                |6.11554022988506  |\n",
      "|RedditFilmsProduction|5.654348591549297 |\n",
      "|AbandonedPorn        |3.165667858303543 |\n",
      "|atheism              |1.785263157894736 |\n",
      "|quotes               |1.8733333333333313|\n",
      "|AskReddit            |7.2520000000000024|\n",
      "|personalfinance      |7.143205128205128 |\n",
      "|Animals              |2.4120000000000026|\n",
      "|leagueoflegends      |2.0991029900332236|\n",
      "|AskReddit            |6.541960784313726 |\n",
      "|videos               |6.7040822644847395|\n",
      "|trees                |10.441111111111113|\n",
      "|Games                |9.338620689655173 |\n",
      "+---------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Define the syllable count function\n",
    "def syllable_count(word):\n",
    "    # If the word is not alphabetic, return 0 (e.g., for numbers or symbols)\n",
    "    if not word.isalpha():\n",
    "        return 0\n",
    "    \n",
    "    word = word.lower()  # Ensure the word is in lowercase\n",
    "    count = 0\n",
    "    vowels = \"aeiou\"\n",
    "    \n",
    "    # Check the first letter\n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    \n",
    "    # Count syllables in the rest of the word\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            count += 1\n",
    "    \n",
    "    # Special case: Subtract 1 if the word ends with 'e' (unless 'e' is preceded by a vowel)\n",
    "    if word.endswith(\"e\") and (len(word) > 1 and word[-2] not in vowels):\n",
    "        count -= 1\n",
    "    \n",
    "    # Ensure that a word has at least one syllable\n",
    "    if count == 0:\n",
    "        count += 1\n",
    "    \n",
    "    # Limit reasonable syllable count (this can be adjusted based on context)\n",
    "    if count < 10:  # Reasonable cap for most English words\n",
    "        return count\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Define the function to calculate the reading level (Flesch-Kincaid)\n",
    "def reading_level(list_of_sentences):\n",
    "    # Flatten the list of lists into a single list of words\n",
    "\n",
    "    total_words = 0\n",
    "    total_syllables = 0\n",
    "    total_sentences = 0  # Since each row represents one sentence (as split by punctuation)\n",
    "\n",
    "    # Iterate over each word in the flattened list and calculate total words and syllables\n",
    "    for sentence in list_of_sentences:\n",
    "        \n",
    "        words_in_sentence = 0\n",
    "        syllables_in_sentence = 0\n",
    "        \n",
    "        # Iterate over each word in the sentence\n",
    "        for word in sentence:\n",
    "            # Skip empty strings or unwanted characters (e.g., newlines)\n",
    "            word = word.strip(\",. !?:*()[]\")\n",
    "            if word.isalpha():  # Ensure the word is alphabetic\n",
    "            words_in_sentence += 1  # Increment word count\n",
    "            syllables_in_sentence += syllable_count(word)  # Add syllables for the word\n",
    "                \n",
    "        if words_in_sentence > 0 and words_in_sentence < 25: # Only add reasonable values\n",
    "            total_words += words_in_sentence\n",
    "            total_syllables += syllables_in_sentence\n",
    "            total_sentences += 1\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if total_words == 0 or total_sentences == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calculate the Flesch-Kincaid readability index with the formula:\n",
    "    # Reading Level = 0.39 * (total_words / total_sentences) + 11.8 * (total_syllables / total_words) - 15.59\n",
    "    level = 0.39*(total_words / total_sentences) + 11.8*(total_syllables / total_words) - 15.59\n",
    "    return level\n",
    "\n",
    "# # Define the UDF for reading level calculation\n",
    "# def reading_level_udf(sentence_list):\n",
    "#     return float(reading_level(sentence_list))\n",
    "\n",
    "# Register the UDF\n",
    "udf_reading_level = udf(lambda sentence_list: reading_level(sentence_list))\n",
    "\n",
    "# Apply the UDF to calculate the reading level for each row\n",
    "df_with_reading_level = df_words.withColumn(\"reading_level\", udf_reading_level(\"content_split\"))\n",
    "\n",
    "# Show the result\n",
    "df_with_reading_level.select(\"subreddit\", \"reading_level\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2189d546-24d0-4070-9807-364bcbb80822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a couple of rows for debug\n",
    "\n",
    "df_with_reading_level.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a0aad15-34da-4632-8a9f-1d7b99e7cfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:======================================================>(146 + 1) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|           subreddit| Avg_reading_level|\n",
      "+--------------------+------------------+\n",
      "|               anime| 5.573502120644817|\n",
      "|          MensRights| 5.664586099629072|\n",
      "|              travel| 5.236568306859009|\n",
      "|londonfootballmeetup| 3.759723514431316|\n",
      "|               HPMOR| 6.007643517559738|\n",
      "|     youtubecomments| 4.190449052872008|\n",
      "|        SaltLakeCity| 4.787569081816676|\n",
      "| UnresolvedMysteries|  5.49423359805998|\n",
      "|          MLBTheShow| 4.315600725046564|\n",
      "|           metro2033|6.4023427664974655|\n",
      "|        marvelheroes| 4.673674815395976|\n",
      "|             DRKCoin| 5.263462619218381|\n",
      "|              AdPorn| 5.212461791974269|\n",
      "|          costa_rica| 5.036286825136762|\n",
      "|          television|  5.45124581114763|\n",
      "|  Anarcho_Capitalism| 6.554010868398792|\n",
      "|    fatpeoplestories|3.7711554108652505|\n",
      "|       SanJoseSharks| 4.401430040561392|\n",
      "|              Hawaii| 5.465975916369529|\n",
      "|             wilfred|5.1613236841850965|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_average_grade = df_with_reading_level.groupBy(\"subreddit\").agg(avg(\"reading_level\").alias(\"Avg_reading_level\"))\n",
    "df_average_grade.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06336e15-a8dc-4c18-9955-90a9b90f83d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 best Subreddits:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|subreddit          |avg_reading_level |\n",
      "+-------------------+------------------+\n",
      "|Webkinz            |27.597142857142853|\n",
      "|PokePlazaReferences|26.490000000000006|\n",
      "|SilphRoadMtnWest   |26.490000000000006|\n",
      "|tacocovers         |20.980000000000008|\n",
      "|faget              |20.590000000000007|\n",
      "|spacecats          |20.200000000000006|\n",
      "|italians           |19.27181818181818 |\n",
      "|ClannadDiscussion  |16.549704163328652|\n",
      "|Interlocken        |16.46166666666667 |\n",
      "|reddit_court       |15.895            |\n",
      "+-------------------+------------------+\n",
      "\n",
      "Top 10 worst Subreddits:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:======================================================(147 + 0) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+\n",
      "|subreddit         |avg_reading_level  |\n",
      "+------------------+-------------------+\n",
      "|cryptoparadise    |-15.200000000000001|\n",
      "|Voting            |-15.2              |\n",
      "|VideoLinkBot      |-15.2              |\n",
      "|theunexplained    |-15.2              |\n",
      "|RedditPersonality |-15.2              |\n",
      "|CIRCLEJERKMILITIA |-15.2              |\n",
      "|EXRBOAHRMOID      |-15.2              |\n",
      "|sixthworldproblems|-14.810847212165097|\n",
      "|spookyspider      |-14.067014954742227|\n",
      "|newsokunomoral    |-13.25             |\n",
      "+------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Top 10 subreddits with the worst (lowest) reading level\n",
    "top_10_best = df_average_grade.orderBy(\"avg_reading_level\", ascending=True).limit(10)\n",
    "\n",
    "# Top 10 subreddits with the best (highest) reading level\n",
    "top_10_worst = df_average_grade.orderBy(\"avg_reading_level\", ascending=False).limit(10)\n",
    "\n",
    "print(\"Top 10 best Subreddits:\")\n",
    "top_10_worst.select(\"subreddit\", \"avg_reading_level\").show(truncate=False)\n",
    "\n",
    "print(\"Top 10 worst Subreddits:\")\n",
    "top_10_best.select(\"subreddit\", \"avg_reading_level\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1212e91e-5a1f-456f-9d7b-c677dc7f814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = df_with_reading_level.select(\"reading_level\").limit(5000).toPandas()\n",
    "\n",
    "# Plot histogram\n",
    "plt.hist(pdf[\"reading_level\"], bins=10, edgecolor=\"black\")\n",
    "plt.xlabel(\"Reading Level\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Reading Levels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1dbf2f-6ff0-4a02-a15a-516ddd0f3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot histogram\n",
    "plt.hist(pdf[\"reading_level\"], bins=30, edgecolor=\"black\")\n",
    "plt.xlabel(\"Reading Level\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Reading Levels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a70270ab-fd7a-492b-9bd9-6ae36558a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791cbf03-a7d1-49e6-a79a-d9c1bf72a4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
